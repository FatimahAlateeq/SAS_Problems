### Standard operating procedure (SOP): BioEquivalence Statistical Analytics of 2x2 cross over study using SAS Software

____

### Before start: This Note's info

**Department:** Statistics.

**Project:** Bioequivalence. 

**Last Update:** 23/Oct/2024

**Version:** 1.0

**Is it an official copy?** No, This is a <u>draft copy</u>.

**Edited by:** Fatimah in 23/Oct/2024.

___

**Editor notes 23/Oct/2024:**

1. This copy of SOP'S uses a personal account of <u>[SAS OnDemand For Academics](https://welcome.oda.sas.com/)</u>. This account is a 1 year free trail, now it is 6 months remaining. (version info: 
   
   ```
     Release: 3.81 (Enterprise Edition)
     Build date: 27 Apr 2022 13:21:36  
     SAS release: 9.04.01M7P08062020  
     SAS platform: Linux LIN X64 5.14.0-284.30.1.el9_2.x86_64  
     Site name: SAS ONDEMAND FOR ACADEMICS  
     Site number:70094220
   ```
   
   )

2. This copy of SOP'S uses a work account of MicroSoft Excel to manage <u>.xlsx</u> files. (version info: 
   
   ```
   Microsoft® Excel® for Microsoft 365 MSO (Version 2305 Build 16.0.16501.20074) 64-bit 
   ```
   
   )

3. All shown sensitive data in this note is fake (concentrations also faked), but have same appearance.

4. This note suitable for 2 sequences x 2 period cross over study.

5. These procedures need prior knowledge and  basic skills about programming debugging (at least Python *or* SAS *or* R...etc).

6. You need internet.

7. I advice you to have some basic information of SAS interface. (less than 1 hour to learn about it, its free in internet).

8. Each code is related to a previous procedure's code.

9. I am not sure about my calculations (I did not validate them yet).

##### Definition:

**PI**: Principal Investigator.

___

### Procedures

#### 0. Prepare folder of raw files

**0.1** Make copy of any file you receive and store the original and the copy in folder of raw files for the specific study with version number. (example folder name: /raw files of Panadol-Paracetamol BioEq Study/).

**0.2** Organize your files with meaningful names and versions with dates of edits 

**0.3** Write <u>.txt</u> file that describe the folder contents and ideas and any important info in detail. (example folder name: /raw files of Panadol-Paracetamol BioEq Study/info.txt).

#### 1. Have SAS Software and .xlsx manager software

**1.1** Get your own work <u>username</u> and <u>password</u> from licensed account of SAS software by your company.

**1.2** Prepare a tool to manage <u>.xlsx</u> files (examples: *Microsoft Excel*, *Google Sheets*. **DO NOT** use personal accounts! only your work licenced accounts).

#### 2. Data pre-processing (preparing data using Excel)

**2.1** You supposed to receive the data in this form or similar in <u>.xlsx</u> file type: 

![figure: raw data](images/2024-10-21-11-26-52-image.png)

**2.2** `Time-Point` columns **most NOT** contain empty value, symbols, strings, nor Characters, **Only** numbers. (example: see *yellow* cells in [figure: raw data]). If it contains unacceptable values contact the *PI*. **DO NOT** Edit them without a permission via formal Email from the *PI* (WhatsApp, Call, Speech, Face to face,...etc. Are **NOT** acceptable, **ONLY** Email).

**2.3** Rearrange the data in a proper form as structured table, without descriptive statistics. (example: see *orange* cells in [figure: raw data]).

**2.4** Raw data most contains these info: `subject number`, `sequence`, `treatment`(test drug, reference drug), `time-points`. If the raw data missing any of them, you **CAN NOT** do analysis, ask *PI* to receive the data again with complete info.

**2.5** Clean data supposed to be like this table: (`period` could be generated by you, if did not received in the raw data)

![figure: clean data](images/2024-10-21-12-04-44-image.png)

**2.6** Generate new column named `period` from `sequence` and `treatment` using a correct formula. (example: ![](images/2024-10-21-12-13-35-image.png)). This column describes the period of the drug have been taken in.

#### 3. Importing cleaned data to SAS and environment preparing

**3.1** Import cleaned data type <u>.xlsx</u> file into SAS environment. 

1. Get into your SAS account <u><a href="https://welcome.oda.sas.com/">SAS OnDemand For Academics</a></u> >> select folder `sasuser.v94` >> click import icon>> [see figure: SAS import .xlsx file]
       ![figure: SAS import .xlsx file 3.1.1](images/2024-10-22-09-58-27-image.png)
   ![figure: SAS import .xlsx file 3.1.2](images/2024-10-22-10-15-06-image.png)

2. Drop down the folder `sasuser.v94`, find our <u>.xlsx</u> file then copy its path from its properties.
   ![figure: SAS import .xlsx file 3.2.1](images/2024-10-22-10-30-44-image.png)

3. Open new SAS page and save it to name it (ctrl+s).
   ![figure: SAS open new SAS-page 3.3.1](images/2024-10-22-10-35-51-image.png)![](images/2024-10-22-10-45-15-image.png)

4. Now you can write SAS codes. follow this code and read my comments that explain every line

5. To run any line or any couple of lines, or all page: select the lines>>click the <u>runner-man icon</u>.
   
   ```sas
   /* import .xlsx file into this workspace */
   libname lib03 XLSX "/home/u6******0/sasuser.v94/Table_of_Concentration.xlsx"; * paste the copied path;
   
   /* copy the data into 'work' library, by importing the worksheet name, mine is:TOC_clean */
   data work.my_data;
       set lib03.'TOC_clean'n;
       * you can filter subjects in this step using this line for Example: 
        Where 'subject number'n not eq 4;
   run;
   ```

6. **What if you faced Errors?** read them and figure out your mistakes or copy the error and paste it in browser search and find the solution (use your debugging skills).

#### 4. Prepare variables

**4.1** Do macros to make it easy when you call variables in the SAS-Procedures(proc).

**4.2** Transform `Time-points` columns to 2-columns named `Time_point` and `concentration_value`, that to apply the procs easily with correct analysis. 

```sas
/* make macro for each neaded variable */
%let my_data=my_data;
%let subj='subject number'n;
%let sequ=sequence;
%let trt=treatment;
%let prd=period;
%let parameters=0 0.08 0.25 0.5 0.75 1 1.33 1.67 2 2.33 2.67 3 3.33 3.67 4 4.5 5 6 8 10 12 16 24 36 48;
* these are the time points from the data;

/* transform time-points */
%let length_parameters=%sysfunc(countw(&parameters, %str(' '))); * '%sysfunc(countw()' conceders the '.' as separator so I add '%str(' ')' argument. this macro is to get count of the parameters;

data transformed;
    set &my_data;
    array parameters &parameters; * Create an array for the parameters;
    array parameters_names{&length_parameters} $ &parameters; * Corresponding names for the array;
    do i=1 to &length_parameters; * Loop through each parameter;
        time_point=input(strip(vname(parameters{i})), 8.); * Get the name of the time point;
        concentration_value=input(strip(parameters{i}), 8.); * Get the value of concentration at that time point;
        output; * Output the transformed row;
    end;
    drop i &parameters; * Drop the loop variable 'i' and transformed parameters;
run;

proc sort data=transformed; * sort the data, it is needed for next steps;
    by &subj &sequ &trt &prd; * I call a macro after '&' sign;
run; 
```

#### 5. Calculations

**5.1** You need some calculations like C_max, AUC, T_max,...etc.

```sas
/* calculations */
*calculate AUC using Trapezoid technique;
DATA auc_temp;
    SET transformed;
    by &subj &sequ &trt &prd;
    LagTime=LAG(time_point);
    LagValue=LAG(concentration_value);

    IF time_point=0 THEN
        DO;
            LagTime=0;
            LagValue=0;
        END;
    Trapezoid=(time_point-LagTime)*(concentration_value+LagValue)/2;
RUN;

* calculate geomean with limits, and cv;
proc surveymeans data=transformed geomean UGMCLM LGMCLM CV alpha=.1;
    /* class 'subject number'n sequence type prd; */
    by &subj &sequ &trt &prd;
    var concentration_value;
    where not concentration_value eq 0;
    * some calculations does not accept 0 value;
    ods output summary=summary;
    ods output statistics=statistics;
    ods output summaryPanel=summarypanel;
    ods output geometricmeans=geometricmeans;
run;

data geo_temp;
    merge summary (where=(Label1='Number of Observations')) statistics 
        geometricmeans;
    rename geomean=geomean u1sideclgm=upper_gmc_lm_90 l1sideclgm=lower_gmc_lm_90 
        cv=cv;
    drop label1 cvalue1 nValue1 varname;
run;

/* *calculat c_max, total AUC, t_max, and logs; */
proc sql;
    create table cmax_auc_temp as select &subj, &sequ, &trt, &prd, 
        avg(concentration_value) as mean, std(concentration_value) as stdv, 
        max(concentration_value) as cmax , sum(Trapezoid) as auc_0t , 
        log(max(concentration_value)) as log_Cmax, log(sum(Trapezoid)) as log_auc_0t 
        from auc_temp group by &subj, &sequ, &trt, &prd;
quit;

proc sql;
    create table cmax_auc as select cmax_auc_temp.*, transformed.time_point as 
        t_max, geo_temp.geomean, geo_temp.gmstderr, geo_temp.cv, 
        geo_temp.lower_gmc_lm_90, geo_temp.upper_gmc_lm_90 from cmax_auc_temp left 
        join transformed on cmax_auc_temp.cmax=transformed.concentration_value left 
        join geo_temp on cmax_auc_temp.&subj=geo_temp.&subj and 
        cmax_auc_temp.&sequ=geo_temp.&sequ and cmax_auc_temp.&trt=geo_temp.&trt and 
        cmax_auc_temp.&prd=geo_temp.&prd
order by &subj, &sequ, &trt, &prd;
quit;

title color=red "Calculations Table summary";

proc print data=cmax_auc;
run;

title;
```

#### 6. Outliers detection

**6.0** Outliers are values at the extreme ends of a dataset. Some outliers represent true values from natural variation in the population. Other outliers may result from incorrect data entry, equipment malfunctions, or other measurement errors. 

**6.0.1** When you find outliers, report the *PI* about the outlier observation, with the used statistical test's result that appears it.

**6.1** You need to encode categorical variables to apply models.

```sas
*** make macros ***;
%let data_set=calcs_summary;
%let id=&subj;
%let categorical_variables=&sequ &trt; * select catigorical variables to encode them next step;
%let independent_variables=e_&sequ e_&trt &prd; * 'e_' means encoded;
%let dependent_variables=Cmax auc_0t;

* encoding categorical variables, it is needed to apply models;
%macro label_encode(dataset,var);
   proc sql noprint;
     select distinct(&var)
     into:val1-
     from &dataset;
 select count(distinct(&var))  into:mx from &dataset;
 quit;
 data &dataset;
     set &dataset;
   %do i=1 %to &mx;
     if (compress(strip(&var), '() /') = compress("&&&val&i", '() /')) then e_&var=&i;
   %end;
   run;
 %mend;
%macro encode_list_variables(dataset, var_list);
   %let var_count = %sysfunc(countw(&var_list));
   %do j = 1 %to &var_count;
     %let var = %scan(&var_list, &j);
     %label_encode(&dataset, &var);
   %end;
%mend;

*use the function;
%encode_list_variables(&data_set, &categorical_variables);

proc sort data=&data_set; by &independent_variables; run;
```

**6.2** How to check the encoded category reference? It easy, i did not delete the reference category. So, you can matching them by row.

**6.3** Test the normality of data.

```sas
*** make normality tests ***;
title color=brown "Normality Tests";

proc univariate data=&data_set normal;
    by &independent_variables;
    id &id;
    ods select TestsforNormality histogram qqplot;
    var &dependent_variables;
    histogram &dependent_variables/normal;
    qqplot &dependent_variables;
run;
```

**6.4** Use `cooksd`, `rstudentbyleverage` tests to detect outliers.

```sas
title color=bip "Outliers detection using (cooksd, rstudentbyleverage)";
ods graphics on;
*** i used defult cutoffs: rstudent cutoff=+-2 and cutoff Cook's is 4/(n-p) ***;

proc reg data=&data_set plots(only label)=(cooksd rstudentbyleverage);
    ODS SELECT CooksDPlot RStudentByLeverage;
    by &independent_variables;
    id &id;
    model &dependent_variables=&independent_variables;
run;
title;
```

**6.5** Also, use another test called `IQR` to detect outliers. (i'll mention it later)

**6.5.1** You need to transform data again. A column for needed parameters names (cmax, auc,...etc) and column for their values. 

```sas
*** transform data to make IQR and z-score tests***;
%let parameters= &dependent_variables;
%let length_parameters=%sysfunc(countw(&parameters));
data transformed;
    set &data_set;
    array parameters &parameters; * Create an array for the parameters;
    array parameters_names{&length_parameters} $ &parameters; * Corresponding names for the array;
    do i = 1 to &length_parameters; * Loop through each parameter;
        parameter_name = vname(parameters{i}); * Get the name of the variable;
        parameter_value = parameters{i}; * Get the value from the parameters array;
        output; * Output the transformed row;
    end;
    drop i &dependent_variables; * Drop the loop variable 'i' and transformed columns of parameters;
run;
proc sort data=transformed; by parameter_name &independent_variables; run; * needed step to avoid error in following steps;
```

**6.5.2** Here is the IQR test, This test is suitable for normal-distributed and skewed data too.

```sas
title color=bip "Outliers detection using (iqr)";
proc univariate data=transformed noprint;
    by parameter_name &independent_variables;
    var parameter_value;
    output out=quartiles pctlpre=Q pctlpts=25, 75;
run;
data bounds_temp;
    set quartiles;
    IQR = Q75 - Q25; /* Calculate IQR */
    Lower_Bound_iqr = Q25 - 1.5 * IQR; /* Lower bound */
    Upper_Bound_iqr = Q75 + 1.5 * IQR; /* Upper bound */
run;
data iqr_results; * a merge step, here is the ooutliers detection;
    merge bounds_temp transformed; /* Get bounds */
    by parameter_name &independent_variables;
    if parameter_value < Lower_Bound_iqr or parameter_value > Upper_Bound_iqr then outlier = 'outlier';
    else outlier = '';
run;
proc print data=iqr_results; run;
```

**6.6** Also, use another test called `z-score` to detect outliers, this test highly sensitive to the mean, so if the data is not normally distributed, i prefer to ignore it. This test usually shows one outlier for each group.

```sas
title color=bibg "Outliers detection using (z-score)";
*** create new variable that shows z-scores for each raw data value***;
*** z-score cutoff=+-3;
proc sql;
create table result_Zscores as
    select transformed.*, (parameter_value - mean(parameter_value)) / std(parameter_value) as z_scores, case when (parameter_value - mean(parameter_value)) / std(parameter_value) NOT BETWEEN -3 AND 3 THEN "Outlier" ELSE "" END AS outlier_flag
    from transformed
    group by parameter_name, &sequ, &trt, &prd
    order by parameter_name, &sequ, &trt, &prd, &id;quit;
proc print data=result_Zscores; run;
```

**6.7** When you find more than three tests detected same outliers, or found a test that shows a very strong outliers, you can classify them as outliers.

**6.8** When you have outliers tell to the *PI*, and analyse your data **with** and **without** the outliers, and report your analysis with and without the outliers.

#### 7. Statistical Analysis

*(To be continued)*

#### 8. Report results

*(To be continued)*

#### 9. Validations

*(I have no idea how to validate the results yet)*

#### 10. References

*(To be continued)*
